import streamlit as st
import requests
import asyncio
import aiohttp
from aiohttp import ClientTimeout
from bs4 import BeautifulSoup
from similar import jaccard_similarity
import json
import pyperclip
import nest_asyncio
import time

# Initialize page config
st.set_page_config(page_title="ğŸŒŸ å¤šç½‘ç«™çˆ¬è™«ç³»ç»Ÿ (å¼‚æ­¥+ç¼“å­˜)", layout="wide")

# Apply nest_asyncio to make async work with Streamlit
nest_asyncio.apply()

# Constants
AFL_BASE_SEARCH_URL = 'https://api.c2k2y3nvy0-heuschena1-p1-public.model-t.cc.commerce.ondemand.com/occ/v2/B2C-AFL-DE/products/search'
AFL_BASE_DETAIL_URL = 'https://api.c2k2y3nvy0-heuschena1-p1-public.model-t.cc.commerce.ondemand.com/occ/v2/B2C-AFL-COM/products/'


# Async fetch function with timeout
async def fetch(session, url, params=None, headers=None):
    if headers is None:
        headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        timeout = ClientTimeout(total=10)
        async with session.get(url, params=params, headers=headers, timeout=timeout) as response:
            response.raise_for_status()
            return await response.text()
    except Exception as e:
        print(f"è¯·æ±‚é”™è¯¯: {e}")
        return ""


# Cache the search results
@st.cache_data(show_spinner="ğŸ” æ­£åœ¨æœç´¢...", ttl=3600)
def cache_search_results(html_content, site, productname):
    if site == "maomao":
        return parse_mao_mao_results(html_content, productname)
    elif site == "asianfood":
        return parse_asian_food_results(html_content, productname)
    return []


# Cache the detail results
@st.cache_data(show_spinner="ğŸ” æ­£åœ¨è·å–è¯¦æƒ…...", ttl=3600)
def cache_detail_results(detail_content, site):
    if site == "maomao":
        return parse_mao_mao_detail(detail_content)
    elif site == "asianfood":
        return parse_asian_food_detail(detail_content)
    return {}


# Async MaoMao search
async def async_search_mao_mao(productname):
    base_url = 'https://mao-mao.de/search'
    params = {'q': productname, 'options[prefix]': 'last'}

    async with aiohttp.ClientSession() as session:
        html = await fetch(session, base_url, params=params)
        return cache_search_results(html, "maomao", productname)


# Parse MaoMao search results
def parse_mao_mao_results(html, productname):
    soup = BeautifulSoup(html, 'html.parser')
    products = soup.select('div.grid-product')
    results = []

    for div in products:
        link_tag = div.find('a', class_='grid-item__link')
        name_tag = div.find('div', class_='grid-product__title')
        price_tag = div.select_one('span.grid-product__price--current span.visually-hidden')
        img_tag = div.find('img')

        if name_tag and link_tag:
            name = name_tag.get_text().strip()
            url = 'https://mao-mao.de' + link_tag.get('href')
            price = price_tag.get_text().strip() if price_tag else "N/A"
            image_src = img_tag.get('data-src') or img_tag.get('src')
            if image_src:
                image_src = f"https:{image_src}" if image_src.startswith("//") else f"https://mao-mao.de{image_src}"

            results.append({
                "name": name,
                "url": url,
                "price": price,
                "image_url": image_src,
                "similarity": jaccard_similarity(productname, name)
            })

    return sorted(results, key=lambda x: x['similarity'], reverse=True)


# Async MaoMao detail
async def async_get_mao_mao_detail(url):
    async with aiohttp.ClientSession() as session:
        html = await fetch(session, url)
        return cache_detail_results(html, "maomao")


# Parse MaoMao detail
def parse_mao_mao_detail(html):
    try:
        soup = BeautifulSoup(html, 'html.parser')

        # åŸºæœ¬ä¿¡æ¯
        product_name_tag = soup.find('h1', class_='product-single__title')
        price_tag = soup.select_one('span.product__price span.visually-hidden')

        # åˆå§‹åŒ–è¿”å›æ•°æ®
        description = ""
        storage_info = ""
        preparation_info = ""

        # é¦–å…ˆå°è¯•ç›´æ¥è·å–å•†å“æè¿°
        description_section = soup.find('div', {'id': 'dropdownContent1D'})
        if description_section:
            # ä½¿ç”¨ at-rte ç±»æ¥å®šä½å®é™…çš„æè¿°æ–‡æœ¬
            rte_content = description_section.find('div', class_='at-rte')
            if rte_content:
                # è·å–æ‰€æœ‰æ®µè½ï¼Œä½†æ’é™¤å­˜å‚¨è¯´æ˜å’Œå‡€é‡ä¿¡æ¯
                paragraphs = []
                for p in rte_content.find_all('p'):
                    text = p.get_text(strip=True)
                    if text and not any(keyword in text.lower() for keyword in [
                        'aufbewahrungs', 'verwendungshinweise', 'nettogewicht',
                        'kÃ¼hl und trocken', 'gramm', 'g das produktdesign'
                    ]):
                        paragraphs.append(text)
                description = '\n'.join(paragraphs)

        # è·å–å­˜å‚¨ä¿¡æ¯
        storage_section = soup.find(string=lambda text: text and 'Aufbewahrungs- und Verwendungshinweise' in text)
        if storage_section:
            # è·å–ç´§è·Ÿåœ¨å­˜å‚¨è¯´æ˜æ ‡é¢˜åçš„æ®µè½
            storage_p = storage_section.find_next('p')
            if storage_p:
                storage_info = storage_p.get_text(strip=True)

        # å¦‚æœä¸Šé¢çš„æ–¹æ³•æ²¡æ‰¾åˆ°å­˜å‚¨ä¿¡æ¯ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if not storage_info:
            storage_keywords = ['KÃ¼hl und trocken lagern', 'Nach dem Ã–ffnen']
            for keyword in storage_keywords:
                storage_text = soup.find(string=lambda text: text and keyword in text)
                if storage_text:
                    storage_info = storage_text.strip()
                    break

        # è·å–é…æ–™ä¿¡æ¯
        ingredients = ""
        ingredients_sections = soup.find_all('span', class_='metafield-multi_line_text_field')
        if ingredients_sections:
            ingredients = ingredients_sections[0].get_text(strip=True)

        # è·å–è¥å…»ä¿¡æ¯
        nutrition_info = {
            "Brennwert": "",
            "Fett": "",
            "- davon gesÃ¤ttigte FettsÃ¤uren": "",
            "Kohlenhydrate": "",
            "- davon Zucker": "",
            "EiweiÃŸ": "",
            "Salz": ""
        }

        if len(ingredients_sections) > 1:
            nutrition_text = ingredients_sections[1].get_text(separator='\n').strip()
            for line in nutrition_text.split('\n'):
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    if key in nutrition_info:
                        nutrition_info[key] = value.strip().replace(',', '.')

        # è·å–ä¸»å›¾ç‰‡
        image_src = None
        image_element = soup.select_one('div.product__main-photos img')
        if image_element:
            image_src = image_element.get('data-src') or image_element.get('src')
            if image_src:
                if image_src.startswith("//"):
                    image_src = f"https:{image_src}"
                elif image_src.startswith("/"):
                    image_src = f"https://mao-mao.de{image_src}"

        return {
            "name": product_name_tag.get_text().strip() if product_name_tag else "æœªçŸ¥äº§å“",
            "price": price_tag.get_text().strip() if price_tag else "N/A",
            "description": description,
            "storage_info": storage_info,
            "preparation_info": preparation_info,
            "ingredients": ingredients,
            "nutrition": nutrition_info,
            "image_url": image_src
        }

    except Exception as e:
        print(f"æå–å•†å“è¯¦æƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}


# Async AsianFoodLovers search
async def async_search_asian_food(productname):
    params = {
        'query': productname,
        'currentPage': 0,
        'pageSize': 21,
        'lang': 'de_DE',
        'curr': 'EUR'
    }

    async with aiohttp.ClientSession() as session:
        response_text = await fetch(session, AFL_BASE_SEARCH_URL, params=params)
        return cache_search_results(response_text, "asianfood", productname)


# Parse AsianFoodLovers search results
def parse_asian_food_results(json_text, productname):
    try:
        data = json.loads(json_text)
        results = []

        for product in data.get("products", []):
            code = product.get('code')
            name = product.get('commercialName', '')
            price = f"{product.get('price', {}).get('value', 'N/A')} â‚¬"

            results.append({
                "name": name,
                "url": code,
                "price": price,
                "similarity": jaccard_similarity(productname, name)
            })

        return sorted(results, key=lambda x: x['similarity'], reverse=True)
    except Exception as e:
        print(f"è§£æ AsianFoodLovers ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []


# Async AsianFoodLovers detail
async def async_get_asian_food_detail(productid):
    async with aiohttp.ClientSession() as session:
        response_text = await fetch(
            session,
            f"{AFL_BASE_DETAIL_URL}{productid}",
            params={'lang': 'de_DE', 'curr': 'EUR'}
        )
        return cache_detail_results(response_text, "asianfood")


# Parse AsianFoodLovers detail
def parse_asian_food_detail(json_text):
    try:
        data = json.loads(json_text)
        image_url = None
        if 'images' in data and len(data['images']) > 0:
            image_url = data['images'][0].get('url')

        return {
            "name": data.get('commercialName', ''),
            "price": f"{data.get('price', {}).get('value', '')} â‚¬",
            "description": data.get('description', ''),
            "ingredients": data.get('ingredients', ''),
            "image_url": image_url,
            "url": data.get('code', ''),
            "allergyInformation": '; '.join([a['description'] for a in data.get('allergyInformation', [])]),
            "origin": '; '.join([c['name'] for c in data.get('countriesOfOrigin', [])])
        }
    except Exception as e:
        print(f"è§£æ AsianFoodLovers è¯¦æƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {}


# Display search results
def display_search_results(results, site_name, get_detail_func):
    if not results:
        st.write(f"æ²¡æœ‰åœ¨ {site_name} æ‰¾åˆ°ç›¸å…³äº§å“")
        return

    for idx, product in enumerate(results[:5]):
        with st.container():
            cols = st.columns([1, 3, 1])

            with cols[0]:
                if product.get("image_url"):
                    st.image(product["image_url"], width=150)

            with cols[1]:
                st.subheader(product["name"])
                st.markdown(f"ğŸ’¶ **ä»·æ ¼**: {product['price']}")

            with cols[2]:
                detail_key = f"{site_name}_{idx}_detail"
                if st.button("ğŸ” æŸ¥çœ‹è¯¦æƒ…", key=detail_key):
                    with st.spinner("æ­£åœ¨è·å–è¯¦æƒ…..."):
                        details = asyncio.run(get_detail_func(product["url"]))
                        if details:
                            display_product_details(details, site_name)


# Display product details
def display_product_details(details, site_name):
    with st.expander("ğŸ“‹ äº§å“è¯¦æƒ…", expanded=True):
        if details.get('image_url'):
            st.image(details['image_url'], width=300)

        st.markdown(f"ğŸ’¶ **ä»·æ ¼**: {details['price']}")

        if details.get('description'):
            st.markdown("ğŸ“ **å•†å“æè¿°:**")
            st.markdown(details['description'])
            if st.button("ğŸ“‹ å¤åˆ¶æè¿°"):
                pyperclip.copy(details['description'])
                st.success("âœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿!")

        if site_name == "MaoMao":
            if details.get('storage_info'):
                st.markdown("ğŸª **å­˜å‚¨è¯´æ˜:**")
                st.markdown(details['storage_info'])

            if details.get('preparation_info'):
                st.markdown("ğŸ‘¨â€ğŸ³ **å‡†å¤‡è¯´æ˜:**")
                st.markdown(details['preparation_info'])

            if details.get('nutrition'):
                st.markdown("ğŸ“Š **è¥å…»ä¿¡æ¯:**")
                for key, value in details['nutrition'].items():
                    if value:
                        st.markdown(f"- **{key}**: {value}")

        elif site_name == "AsianFoodLovers":
            if details.get('origin'):
                st.markdown("ğŸŒ **äº§åœ°:**")
                st.markdown(details['origin'])

            if details.get('allergyInformation'):
                st.markdown("âš ï¸ **è¿‡æ•ä¿¡æ¯:**")
                st.markdown(details['allergyInformation'])

        if details.get('ingredients'):
            st.markdown("ğŸ§¬ **é…æ–™è¡¨:**")
            st.markdown(details['ingredients'])


# æ–°å¢çš„æ˜¾ç¤ºå‡½æ•°
# def display_detail_section(title, content, key_prefix):
#     if content:
#         col1, col2 = st.columns([4, 1])
#         with col1:
#             st.markdown(f"{title}")
#             st.markdown(content)
#         with col2:
#             copy_status = st.empty()
#             if st.button("ğŸ“‹ å¤åˆ¶", key=f"copy_{key_prefix}"):
#                 pyperclip.copy(content)
#                 copy_status.success("âœ… å·²å¤åˆ¶!")
#                 time.sleep(2)
#                 copy_status.empty()


def display_detail_section(title, content, key_prefix):
    """æ˜¾ç¤ºè¯¦æƒ…éƒ¨åˆ†çš„æ–°å‡½æ•°ï¼Œä½¿ç”¨ Streamlit çš„å¤åˆ¶åŠŸèƒ½"""
    if content:
        st.markdown(f"{title}")
        st.markdown(content)
        st.code(content, language=None)  # ä½¿ç”¨ st.code æ¥æ˜¾ç¤ºå¯å¤åˆ¶çš„æ–‡æœ¬å—


async def main():
    st.title("ğŸŒŸ å¤šç½‘ç«™çˆ¬è™«ç³»ç»Ÿ ğŸŒŸ (å¼‚æ­¥ + ç¼“å­˜)")
    
    # åˆå§‹åŒ– session state
    if 'mao_mao_results' not in st.session_state:
        st.session_state.mao_mao_results = []
    if 'asian_food_results' not in st.session_state:
        st.session_state.asian_food_results = []
    if 'details_visibility' not in st.session_state:
        st.session_state.details_visibility = {}
    if 'details_data' not in st.session_state:
        st.session_state.details_data = {}
    if 'mao_page' not in st.session_state:
        st.session_state.mao_page = 1
    if 'asian_page' not in st.session_state:
        st.session_state.asian_page = 1

    # æœç´¢è¾“å…¥å’ŒæŒ‰é’®
    productname = st.text_input("ğŸ” è¾“å…¥è¦æœç´¢çš„äº§å“å…³é”®è¯:", key="search_input")
    if st.button("ğŸ” å¼€å§‹æœç´¢", key="start_search_button") and productname:
        with st.spinner("æ­£åœ¨å¼‚æ­¥æœç´¢ä¸¤ä¸ªç½‘ç«™..."):
            st.session_state.mao_mao_results, st.session_state.asian_food_results = await asyncio.gather(
                async_search_mao_mao(productname),
                async_search_asian_food(productname)
            )
            st.session_state.details_visibility = {}
            st.session_state.details_data = {}
            st.session_state.mao_page = 1
            st.session_state.asian_page = 1

    # ä½¿ç”¨é€‰é¡¹å¡æ˜¾ç¤ºç»“æœ
    tab1, tab2 = st.tabs(["ğŸ›’ MaoMao", "ğŸ›’ AsianFoodLovers"])

    # MaoMao ç»“æœæ˜¾ç¤º
    with tab1:
        if st.session_state.mao_mao_results:
            per_page = 5
            total_pages = (len(st.session_state.mao_mao_results) + per_page - 1) // per_page

            # åˆ†é¡µå¯¼èˆª
            st.markdown("### ğŸ“„ é¡µé¢å¯¼èˆª")
            prev, page_info, next = st.columns([1, 3, 1])
            with prev:
                if st.button("â¬…ï¸ ä¸Šä¸€é¡µ", key="mao_prev", disabled=st.session_state.mao_page <= 1):
                    st.session_state.mao_page -= 1
            with page_info:
                st.write(f"ç¬¬ {st.session_state.mao_page} é¡µ / å…± {total_pages} é¡µ")
            with next:
                if st.button("ä¸‹ä¸€é¡µ â¡ï¸", key="mao_next", disabled=st.session_state.mao_page >= total_pages):
                    st.session_state.mao_page += 1

            start_idx = (st.session_state.mao_page - 1) * per_page
            end_idx = start_idx + per_page

            # æ˜¾ç¤ºæ¯ä¸ªäº§å“
            for idx, product in enumerate(st.session_state.mao_mao_results[start_idx:end_idx]):
                product_key = f"mao_{idx}_{product['name']}"
                
                with st.container():
                    cols = st.columns([1, 3, 1, 1])
                    
                    with cols[0]:
                        if product.get("image_url"):
                            st.image(product["image_url"], width=150)
                    
                    with cols[1]:
                        st.subheader(product["name"])
                        st.markdown(f"ğŸ’¶ **ä»·æ ¼**: {product['price']}")
                    
                    with cols[2]:
                        if product.get("image_url"):
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½å›¾ç‰‡",
                                data=requests.get(product["image_url"]).content,
                                file_name=f"{product['name']}.jpg",
                                key=f"download_{product_key}"
                            )
                    
                    with cols[3]:
                        if st.button("ğŸ” æŸ¥çœ‹è¯¦æƒ…", key=f"detail_{product_key}"):
                            if product["name"] not in st.session_state.details_data:
                                with st.spinner("æ­£åœ¨è·å–è¯¦æƒ…..."):
                                    st.session_state.details_data[product["name"]] = await async_get_mao_mao_detail(product["url"])
                            st.session_state.details_visibility[product["name"]] = \
                                not st.session_state.details_visibility.get(product["name"], False)

                    # æ˜¾ç¤ºè¯¦æƒ…ä¿¡æ¯
                    if st.session_state.details_visibility.get(product["name"], False):
                        details = st.session_state.details_data[product["name"]]
                        if details:
                            with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯", expanded=True):
                                if details.get('image_url'):
                                    st.image(details['image_url'], width=300)

                                if details.get('description'):
                                    display_detail_section(
                                        "ğŸ“ **å•†å“æè¿°:**",
                                        details['description'],
                                        f"desc_{product_key}"
                                    )

                                if details.get('storage_info'):
                                    display_detail_section(
                                        "ğŸª **å­˜å‚¨è¯´æ˜:**",
                                        details['storage_info'],
                                        f"storage_{product_key}"
                                    )

                                if details.get('preparation_info'):
                                    display_detail_section(
                                        "ğŸ‘¨â€ğŸ³ **å‡†å¤‡è¯´æ˜:**",
                                        details['preparation_info'],
                                        f"prep_{product_key}"
                                    )

                                if details.get('nutrition'):
                                    st.markdown("ğŸ“Š **è¥å…»ä¿¡æ¯:**")
                                    nutrition_text = "\n".join(
                                        [f"{key}: {value}" for key, value in details['nutrition'].items() if value]
                                    )
                                    st.code(nutrition_text, language=None)
                                
                                if details.get('ingredients'):
                                    display_detail_section(
                                        "ğŸ§¬ **é…æ–™è¡¨:**",
                                        details['ingredients'],
                                        f"ingredients_{product_key}"
                                    )

                                st.markdown(
                                    f"""ğŸ”— **äº§å“é“¾æ¥:** <a href="{product['url']}" target="_blank">{product['url']}</a>""",
                                    unsafe_allow_html=True
                                )
        else:
            st.info("æš‚æ—  MaoMao æœç´¢ç»“æœ")

    # AsianFoodLovers ç»“æœæ˜¾ç¤º
    with tab2:
        if st.session_state.asian_food_results:
            per_page = 5
            total_pages = (len(st.session_state.asian_food_results) + per_page - 1) // per_page

            # åˆ†é¡µå¯¼èˆª
            st.markdown("### ğŸ“„ é¡µé¢å¯¼èˆª")
            prev, page_info, next = st.columns([1, 3, 1])
            with prev:
                if st.button("â¬…ï¸ ä¸Šä¸€é¡µ", key="afl_prev", disabled=st.session_state.asian_page <= 1):
                    st.session_state.asian_page -= 1
            with page_info:
                st.write(f"ç¬¬ {st.session_state.asian_page} é¡µ / å…± {total_pages} é¡µ")
            with next:
                if st.button("ä¸‹ä¸€é¡µ â¡ï¸", key="afl_next", disabled=st.session_state.asian_page >= total_pages):
                    st.session_state.asian_page += 1

            start_idx = (st.session_state.asian_page - 1) * per_page
            end_idx = start_idx + per_page

            # æ˜¾ç¤ºæ¯ä¸ªäº§å“
            for idx, product in enumerate(st.session_state.asian_food_results[start_idx:end_idx]):
                product_key = f"afl_{idx}_{product['name']}"

                with st.container():
                    cols = st.columns([1, 3, 1])

                    # äº§å“å›¾ç‰‡
                    with cols[0]:
                        if product.get("image_url"):
                            st.image(product["image_url"], width=150)

                    # äº§å“åŸºæœ¬ä¿¡æ¯
                    with cols[1]:
                        st.subheader(product["name"])
                        st.markdown(f"ğŸ’¶ **ä»·æ ¼**: {product['price']}")

                    # æŸ¥çœ‹è¯¦æƒ…æŒ‰é’®
                    with cols[2]:
                        if st.button("ğŸ” æŸ¥çœ‹è¯¦æƒ…", key=f"detail_{product_key}"):
                            if product["name"] not in st.session_state.details_data:
                                with st.spinner("æ­£åœ¨è·å–è¯¦æƒ…..."):
                                    st.session_state.details_data[product["name"]] = await async_get_asian_food_detail(
                                        product["url"])
                            st.session_state.details_visibility[product["name"]] = \
                                not st.session_state.details_visibility.get(product["name"], False)

                    # æ˜¾ç¤ºè¯¦æƒ…ä¿¡æ¯
                    if st.session_state.details_visibility.get(product["name"], False):
                        details = st.session_state.details_data[product["name"]]
                        if details:
                            with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯", expanded=True):
                                if details.get('image_url'):
                                    st.image(details['image_url'], width=300)

                                # æè¿°ä¿¡æ¯
                                if details.get('description'):
                                    st.markdown("ğŸ“ **å•†å“æè¿°:**")
                                    st.markdown(details['description'])
                                    if st.button("ğŸ“‹ å¤åˆ¶æè¿°", key=f"copy_desc_{product_key}"):
                                        pyperclip.copy(details['description'])
                                        st.success("âœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿!")

                                # äº§åœ°ä¿¡æ¯
                                if details.get('origin'):
                                    st.markdown("ğŸŒ **äº§åœ°:**")
                                    st.markdown(details['origin'])

                                # è¿‡æ•ä¿¡æ¯
                                if details.get('allergyInformation'):
                                    st.markdown("âš ï¸ **è¿‡æ•ä¿¡æ¯:**")
                                    st.markdown(details['allergyInformation'])

                                # é…æ–™ä¿¡æ¯
                                if details.get('ingredients'):
                                    st.markdown("ğŸ§¬ **é…æ–™è¡¨:**")
                                    st.markdown(details['ingredients'])
                                    if st.button("ğŸ“‹ å¤åˆ¶é…æ–™", key=f"copy_ingredients_{product_key}"):
                                        pyperclip.copy(details['ingredients'])
                                        st.success("âœ… å·²å¤åˆ¶åˆ°å‰ªè´´æ¿!")

                                # äº§å“ç¼–ç 
                                st.markdown(f"ğŸ”— **äº§å“ç¼–ç :** {details['url']}")
        else:
            st.info("æš‚æ—  AsianFoodLovers æœç´¢ç»“æœ")


# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    asyncio.run(main())